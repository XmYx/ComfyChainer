# âœ¨ Comfy Batch GUI â€” Multi-Scene Chained Generation (Image â†’ Video â†’ Concat)

A tiny, practical PyQt (qtpy) GUI for running **ComfyUI** in **batch mode** with **multi-scene support**, **prompt chaining**, and a **clean â€œproject folderâ€ workflow**.

This tool is built for one job:

> Generate a **still image per scene** (clean, no dialogue), then generate **video segments from the next prompts**, chaining each segment from the **last frame** of the previous one â€” and optionally **concatenate** everything into a final MP4.

---

## ğŸŒŸ What This Does

### âœ… Multi-Scene, Two-Pass Pipeline
For each scene:

1. **PASS 1:** generate the sceneâ€™s *initial still image* from the **first prompt only**
2. **PASS 2:** generate video segments from prompts **starting at index 1**
3. After each segment, the tool extracts the **last frame** (ffmpeg) and uses it as the **next start image**
4. Optionally **concats** all segments into `final.mp4`

### âœ… â€œFirst Prompt = Image Onlyâ€
This is the core idea.

- Prompt 0 â†’ **IMAGE workflow**
- Prompt 1..N â†’ **VIDEO workflow**

So you can keep your still prompt clean and art-directed, and put dialogue / action / timing in the video prompts.

### âœ… Project Save / Load (Portable)
You can save a **project folder** that contains:
- your **prompt JSON**
- your **image workflow JSON**
- your **video workflow JSON**
- your **settings + bindings** (`project.json`)

Loading that folder restores the entire run configuration in one click.

---

## ğŸ§  Why This Exists

When doing iterative AI animation, you often want:
- one strong establishing frame per scene
- a controlled motion chain without â€œresettingâ€ between segments
- a way to preserve the **exact workflows and prompts used** for reproducibility
- â€œsession managementâ€ (project folders) instead of hunting for file paths

This repo is a simple, opinionated solution.

---

## ğŸ§© Features

- ğŸ§· **Bindings system** to map prompt fields â†’ ComfyUI node inputs  
- ğŸ¬ **Chained video segments** using last-frame extraction (ffmpeg)
- ğŸ§± **Multi-scene support**
- ğŸ² **Seed randomization** (per scene or per generation)
- ğŸ“¦ **Project folder export/import** (everything included)
- ğŸ§¾ `manifest.json` output for auditability + reruns

---

## ğŸ“ Output Structure

A typical run produces:

```

comfy_batch_outputs/
stills/
...initial still images...
videos/
...segment videos...
chain_frames/
...last-frame PNGs used for chaining...
manifest.json
final.mp4   (optional)

````

`manifest.json` includes:
- each sceneâ€™s still
- each segment path
- final concat path (if created)

---

## ğŸ§¾ Prompt JSON Formats

### 1) Single Scene
```json
{
  "segment_sec": 5,
  "prompts": [
    "p0 (image only)",
    "p1 (video)",
    "p2 (video)"
  ]
}
````

### 2) Multi-Scene (list of lists)

```json
{
  "segment_sec": 5,
  "prompts": [
    ["scene1 p0 (image)", "scene1 p1 (video)", "scene1 p2 (video)"],
    ["scene2 p0 (image)", "scene2 p1 (video)"]
  ]
}
```

### 3) Explicit Scenes (recommended for duration expansion)

```json
{
  "segment_sec": 5,
  "scenes": [
    { "prompts": ["s1 p0", "s1 p1", "s1 p2"], "total_seconds": 30 },
    { "prompts": ["s2 p0", "s2 p1"], "total_segments": 8 }
  ]
}
```

---

## ğŸ”— Bindings: The Secret Sauce

Bindings tell the tool how to inject values into your ComfyUI workflow JSON.

Examples youâ€™ll typically bind:

### IMAGE workflow

* `positive` / `prompts` â†’ the image prompt text node
* `negative` â†’ negative prompt field
* `seed` â†’ sampler seed input

### VIDEO workflow

* `positive` / `prompts` â†’ video prompt node
* `negative` â†’ negative prompt node
* `seed` â†’ sampler seed input
* `start_image_path` â†’ your â€œLoad Image (Path)â€ node input (**absolute paths**)

> Tip: make sure your ComfyUI workflow uses a node that accepts a file path string for the starting image.

---

## ğŸ§™ Project Save / Load

### Saving a project

Creates a folder containing:

```
my_project/
  project.json
  prompts.json
  workflow_image.json
  workflow_video.json
```

This means:

* the repo can be used like a â€œmini production systemâ€
* every run can be archived and restored later
* teams can share project folders without missing dependencies

### Loading a project

Restores:

* prompts (and scenes)
* workflows
* bindings
* all UI settings

No re-selecting files. No guessing which workflow version you used.

---

## âš™ï¸ Requirements

* Python 3.9+
* ComfyUI running (local or remote)
* `ffmpeg` available in PATH

### Python deps

Install the basics:

```bash
pip install -r requirements.txt
```

If you donâ€™t have one yet, you likely need:

* `qtpy`
* a Qt backend (`PyQt6`)
* `requests`
* `urllib3`

Example:

```bash
pip install qtpy PySide6 requests urllib3
```

### ffmpeg

Confirm it works:

```bash
ffmpeg -version
ffprobe -version
```

---

## ğŸš€ Running

```bash
python comfy_batch_gui.py
```

Then in the GUI:

1. Set your ComfyUI base URL (default: `http://localhost:8188`)
2. Load your **Prompts JSON**
3. Load your **Image Workflow JSON**
4. Load your **Video Workflow JSON**
5. Add bindings (image + video)
6. Choose output directory
7. Run âœ¨

---

## ğŸª„ Best Practices (Highly Recommended)

* Keep prompt 0 per scene *purely visual* (no dialogue)
* Put speech/intent/action in the subsequent prompts
* Make sure your video workflow:

  * reads `start_image_path`
  * outputs video (gif/mp4) consistently
* Always save a project folder when a run â€œworksâ€ â€” it becomes a reproducible asset

---

## ğŸ§¯ Troubleshooting

### â€œNo video output foundâ€

Your workflow probably outputs under a different field than `videos/gifs`.
Check `parse_best_outputs()` and confirm your Comfy nodes output into:

* `outputs -> videos` or `outputs -> gifs`

### â€œffmpeg not foundâ€

Install ffmpeg and ensure itâ€™s in your PATH.

### â€œTimed out waiting for promptâ€

Increase `max_wait_s` or check your ComfyUI server isnâ€™t stalled.

---

## ğŸ—ºï¸ Roadmap Ideas (if you want to expand)

* per-scene concat + crossfade transitions
* per-segment overrides (CFG, steps, sampler, model switch)
* auto-binding presets for popular workflows
* render queue visualizer (thumbnails + progress per segment)

---

## â¤ï¸ Credits / Philosophy

This repo intentionally stays small and readable.
Itâ€™s not a framework â€” itâ€™s a **tool**.

If youâ€™re building long-form or episodic AI animation, this is meant to be the reliable little workhorse that keeps runs reproducible and chaining stable.

---

## ğŸ“œ License

Choose your vibe:

* MIT for maximum openness
* or keep it private if itâ€™s pipeline code

(If you tell me your preference, I can generate the `LICENSE` file too.)

```
